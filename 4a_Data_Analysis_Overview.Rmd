---
title: MADA Fall 2019 - Data Analysis Overview
subtitle: ""
author: Andreas Handel
institute: "University of Georgia"
date: "`r Sys.Date()`"
#bibliography: ../media/references.bib
output: 
  html_document:
    toc_depth: 3
---

```{r, echo = FALSE}
#just so I can use emoticons
#devtools::install_github("hadley/emo")
library(emo)
```

# Overview
In this module, we will talk about the whole data analysis workflow in a general, big-picture sense before we go into some of the details in further modules.


# Learning Objectives
*	Understand the elements of a data analysis  


# Data Analysis Workflow
The following figure provides a conceptual illustration of the whole data analysis workflow.

![](./media/analysis-workflow.png)

The spiral is meant to indicate that while the different steps in an analysis are rarely linear, things do improve over time until you have the data and code in a form that everything fits and you can produce _final_ results.

In the introductory chapter of their great book R for data Science (R4DS), Garrett Grolemund and Hadley wickham have a similar diagram. 
[Check out the figure and read their short introductory chapter (1.1.) here.](https://r4ds.had.co.nz/introduction.html)

Note that the process of getting the data ready for analysis goes by different names that people use interchangably. So when you hear or read words like _wrangling_, _cleaning_, _processing_ or _tidying_ it often means the same thing. Sometimes people try to distinguish, e.g. _tidying_ could be used to get the data into something called tidy format (we'll talk about that more later), while _processing_ could mean things like dealing with outliers or missing values. In my figure above, I wrote those two terms as separate, while in the R4DS chapter and figure, they distinguish between tidying and transforming and together call them wrangling. You need to guess from the context what is meant, but often you can think of these terms as all meaning similar things.

Let's look at the different components of an analysis in more detail.


# Question & Data Match

**If you start with a boring (or dumb) question or with data that is more or less garbage/noise, or you have a bad question/data match, no part of your analysis matters!**

One could argue that having a good question and suitable data to answer it is part of science/research but not strictly part of the analysis. However, since data analyis is such an integral part of science, and most scientists do both parts, i.e. coming up with questions and data ana analyzing them, it is critical to get this right.

* Option 1: Start with question, find suitable data
* Option 2: Start with data, find suitable question
* Option 3: Iterate between question & data until you have "a match" (most common)

Challenge: To find questions (& data) that are both "big enough" (to be interesting) and "small enough" (to be doable)


## Getting Data
* Collect it yourself
* Get it from a collaborator
* Get it from some (online) database/resource


## Cleaning Data
* Deal with missing values
* Deal with outliers
* Deal with data entry errors
* Turn data into a form ready for analysis
* ...

## Exploratory Data Analysis
* Look at summaries for individual variables
* Slice and dice your data any way you can think of
* Plot everything!
* "Get to know" your data

**Checkpoint:** Hopefully you'll figure out at this stage at the latest if your project is feasible or not, i.e. if you can use the data to answer your question. If not, alter or abandon. Don't keep going hoping against all hope that "magic might happen" and you'll get a good final product after all.


## Pre-process Data
* Scaling
* Centering
* Removing variables or observations
* Removing missing entries
* Building new variables
* ...

The specific pre-processing steps that need to happen depends on the statistical modeling approach(es) you plan on using.

## Analyzing Data
* That's the part most (bio)statistics courses focus on
* You usually spend <25% of your time on this task
* Figure out which approach(es) are suitable for your data
* Analysis method should be dictated by both data and question
* If possible/useful, use multiple approaches
* But beware of "cherry picking" the analyses that give you the results you want. If you analyze data multiple ways, report all results.


## Evaluate Results
* Do the results make sense?
* Is the model appropriate for the data? (Use graphs to check)
* Anything that could have gone wrong?

## Reporting your results
* Figures
* Tables
* Manuscript
* Concise but complete
* Supplementary materials allow you to give as much detail as needed
* Reproducibility is important


## Ideal versus real workflow
* Theoretically/ideally, the data analysis workflow is one-directional
* In reality, there are often back and forths.
* Some things that might happen:
    * Running analysis shows that cleaning/pre-processing wasn't adequate
    * Changing analysis method requires different kinds of cleaning and pre-processing.
    * Evaluating results indicates that something 'isn't quite right' and needs to be fixed
    * Multiple variations of the analysis based on better understanding how to best present results

**Having the whole analysis reproducible and well documented is important**



# Data Analysis Types
No matter what analysis you do, you will need to do the steps of getting and cleaning/processing/wrangling the data. You also always want to explore your data. After that, the further analyis steps you do depend on your goals.

The simplest analysis is a **descriptive** one. At that stage, you process, summarize and present the data, and do not go further. Here, you don't need to fit any statistical models.

* **Analytical/Inferential:** "Statistical Probing" of patterns. e.g. Hypothesis is that there is a negative correlation between age and measles incidence, or that there is a difference between males and females. We can use the right data and model to test if that's true and how strong the correlation is.
* **Predictive:** Given all kinds of information (e.g. gender, age), try to predict future risk of measles infection.
* **Causal:** Trying to show that ice cream causes measles. For that, data needs to be collected in the right way.
* **Mechanistic:** Build a model that explicitly includes mechanisms of measles infection, e.g. a process by which an infected person transmits to a non-infected person. 


### Needs model fitting:
* **Analytical/Inferential: Quantitatively understand relations between inputs/predictors/features and outputs/outcomes**
    * Causal interpretation possible under certain circumstances
* **Predictive: Use information on inputs to predict outputs**
* Mechanistic: Can be used with the right kind of data and models, both in an inferential and predictive way

## Why fit models
* To test hypotheses (e.g. "there is a (linear) _correlation_ between BMI and diabetes")
* To estimate parameters (e.g. "a 1 unit increase of particulate matter leads to 2 more asthma attacks per person per year")
* To make predictions (e.g. " exposure to N cholera bacteria leads to an infection with probability p") 
* To draw causal conclusions (e.g. "taking statins _causes_ reduction in cholesterol")
* To draw mechanistic conclusions (e.g. "interferon reduces HCV virus load _by stopping production of new virus_") 

## Inference as goal
* Focus is on understanding the relation between inputs/predictors/features and outputs/outcome
* Simpler models (e.g. linear/logistic regression, GLM, Classification and Regression Trees) are usually better, allow for easier interpretation of results
* Examples: 
    * Is the relation between some chemical and cancer risk linear, and how much would risk increase if the chemical exposure increased by 1 unit?
    * Understanding which markers (e.g. cytokines in blood) are most influential for a given clinical outcome

## Prediction as goal
* Focus is on predicting (new) output/outcomes based on knowledge of inputs/predictors/features
* Understanding relation between input(s) and output(s) not that important
* High performance, "black box" models (e.g. GAM, Forests, SVM, Neural Nets) are often used.
* Examples: 
    * Netflix/Amazon recommendations based on past behavior
    * Prediction of clinical outcome based on a large set of markers (e.g. cytokines in blood)


## Types of Analyses based on outcome
* If an outcome is known/available, the statistical methods employed are usually called supervised learning methods/algorithms.
    * Example: Look for associations (make predictions) between flu patient characteristics and occurrence of hospitalization.
    
* If an outcome is unknown/unavailable, the statistical methods are called unsupervised learning methods/algorithms.
    * Example: Try to group pictures of cells into categories of normal/abnormal, without knowing for any of the pictures if they are normal or not.

_(Almost) all models you have encountered so far in your work are likely supervised methods._

## Types of Analyses based on outcome

### Outcome is a continuous variable (or can be treated as one)
Regression methods: (generalized) linear models, generalized additive models, trees, support vector machines, neural nets, ...

Examples: Cholesterol level, number of infected cases during outbreak

### Outcome is categorical
Classification Methods: Logistic regression, K-nearest neighbors, Linear Discriminant Analysis, GAM, trees, SVM, NN,...

Examples: Yes/No outcome, low/medium/high responders

## Types of Analyses based on outcome

### Outcome is unknown/does not exist
Clustering methods: K-means clustering, Principal Component Analysis (also used for other purposes), ...

Example: Group gene sequences based on sequence similarity


## The _no free lunch_ theorem
http://en.wikipedia.org/wiki/No_free_lunch_theorem

* There is no method that is universally best for all data/questions
* Even for a given dataset, there are always trade-offs between methods/approaches 

## Machine learning methods
```{r islrfig,  fig.show='hold', out.width = "600px", fig.cap='From: "An Introduction to Statistical Learning with Applications in R" (ISLR) by James et al.', echo=FALSE}
knitr::include_graphics("../media/islr-fig27.png")
```


## Supervised modeling overview
* We consider models where we have a single outcome, Y
* Y can be continuous or categorical
* We usually have multiple predictors, $X_1, X_2,...$
* Sometimes, one of the predictors is our main focus (exposure), and others are covariates
* Sometimes, all predictors are considered equally important


## Continuous modeling approaches
We formulate a model generally as: $Y=f(X_1,X_2,...)+e$

If the outcome Y is continuous, these are some common models:

* Simple Linear model: $Y=b_0 + b_1X_1 + b_2X_2 + ...$
* Linear model with higher orders: $Y=b_0 + b_1X_1 + b_2X_2 + b_3 X_1^2 + b_4 X_2^2 + b_5 X_1X_2 + ...$

## Some comments on modeling approaches

* In statistics, linear refers to the parameters/coefficients. So the previous models are linear
models for statisticians (but not for engineers or physicists)
* If you include higher order terms, the base terms **also need to be in the model**.
* Models with higher order terms ($X^2$, $X^3$, ...) are often called polynomial models
* The interpretation of higher order coefficients is less intuitive.

## Continuous modeling approaches
Many other models can be used for a continuous outcome:

* Models that include piecewise polynomials or splines
* Generalized additive models: $Y=b_0 + f_1(X_1) + f_2(X_2) + ...$
* Regression trees and forests
* Support vector machines
* Neural Nets
* ...

For some of those models, writing down the equation that connects Y with the $X_i$ is often hard or impossible. Instead, the model is described by an algorithm.

## Categorical modeling approaches
We formulate a model generally as: $g(Y)=f(X_1,X_2,...)+e$

If the outcome Y is categorical, these are some common models:

* A simple logistic model: $\log \left( \frac{Y}{1-Y} \right) = b_0 + b_1X_1 + b_2 X_2 + ...$ (Y is now a probability)
* More complicated logistic model: $\log \left( \frac{Y}{1-Y} \right) = b_0 + b_1X_1 + b_1 X_1^2 + f_2(X_2) + ...$ 

**We can do anything with the predictors we did for continuous outcomes**


## Categorical modeling approaches
Many other models can be used for categorical outcomes:

* Linear and Quadratic Discriminant Analysis
* Regression trees and forests
* Support vector machines
* ...

Again, for some of these models, we can't formulate an equation, but we can describe the algorithm.


## Summary
* There are many different modeling approaches
* Most of them are relatively easy to implement in R
* **It's hard to pick the right one! More on that next...**





* Chapters 1 and 2 of _Applied Predictive Modeling_ by Kuhn (in _general resources_ folder). 
* Chapter 2.1 of _An Introduction to Statistical Learning_ by James et al. (in _general resources_ folder). I recommend also reading the introduction, chapter 1. 

## Optional
* [R for Data Science](http://r4ds.had.co.nz/index.html), chapters 22-24.




# Topical Cartoon
![Maybe Dogbert didn't do the analysis quite right](../media/dilbert_datamining.gif)


